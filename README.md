# ðŸ“° Currents News Reporting - Data Engineering Project

## Overview
This project builds an **end-to-end data pipeline** using **Apache Airflow** and **Docker**.  
It fetches live news from the [Currents API](https://currentsapi.services/en), stores it in a database,  
and performs automated analysis to identify top sources and trends.

Developed for **Northwestern University - Fall 2025 Data Engineering Final Project**.

---

## ðŸ§  Project Objectives
- Read data from an API (Currents API)
- Store the API data in a database
- Build a DAG to orchestrate the pipeline using Apache Airflow
- Automate tasks and measure pipeline performance
- Perform exploratory data analysis (EDA) on the news dataset

---

## ðŸ“¦ File Structure

currents-news-reporting/
â”œâ”€â”€ dags/
â”‚ â””â”€â”€ news_pipeline_dag.py # Airflow DAG script
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ news_api_utils.py # API connection and data fetching functions
â”‚ â”œâ”€â”€ db_utils.py # Database helper functions
â”‚ â”œâ”€â”€ analysis_utils.py # Simple EDA functions
â”‚ â””â”€â”€ init.py
â”œâ”€â”€ docker-compose.yaml # Docker configuration for Airflow
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .env.example # Environment variable template (no real API key)
â”œâ”€â”€ .gitignore # Files to ignore in Git
â””â”€â”€ README.md # Project documentation

